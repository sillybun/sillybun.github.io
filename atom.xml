<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[张翼腾的博客]]></title>
  <link href="https://sillybun.github.io/atom.xml" rel="self"/>
  <link href="https://sillybun.github.io/"/>
  <updated>2019-04-01T08:16:18+08:00</updated>
  <id>https://sillybun.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[Word2Vec入门]]></title>
    <link href="https://sillybun.github.io/15540423884690.html"/>
    <updated>2019-03-31T22:26:28+08:00</updated>
    <id>https://sillybun.github.io/15540423884690.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Background</h2>

<p>@todo</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">Model Introduction</h2>

<p>在Word2Vec中，Mikolov提出了两个模型 — Continuous Bag-of-Words（CBOW）模型和Skip-gram（SG）模型。两个模型都有三层：输入层，投影层和输出层。对于CBOW模型，输入上下文预测单词；对于SG模型，通过单词预测上下文。目前来看，一般认为SG的效果好于CBOW模型。</p>

<h3 id="toc_2">CBOW Model</h3>

<p>CBOW包含三层：</p>

<ol>
<li>输入层，包含了context(w)中的2n个单词：\(e(w_{-n}), e(w_{-n+1}), \dots, e(w_n)\)</li>
<li>投影层：投影层是输入层的求和，即：\(x_w = \sum\limits_{i=-n}^{n}e(w_i)\)</li>
<li>输出层：有两种方法：一种是多层的softmax，一种是negative sampling<br/>
优化的函数是：<br/>
\[<br/>
L = \sum\limits_{w\in C}\log \mathrm{P}(w|\mathrm{context}(w))<br/>
\]</li>
</ol>

<h3 id="toc_3">Hierarchical Softmax</h3>

<p>由于如果对词典中的每个单词使用softmax的计算量非常的大，Word2Vec使用了多层的Softmax方法。我们根据词频建立的<a href="15540295441807.html">Huffman树</a>，这棵树包含了\(|D|\)个叶子和\(|D|-1\)个内点，每个叶子节点对应着词典中的一个单词，出现频率比较高的单词深度会比较的浅，因此到达它的路径会更短。由于到叶子的平均深度为\(\log_2|D|\)，所以对于每一个\((w, \mathrm{w})\)，需要训练的向量的个数的数学期望为：\(\log_2|D|\)。<br/>
到每个叶子节点的路径是唯一的，我们做如下的约定：令p为从根到叶子节点w的路径，令\(n(w, j)\)是p上的第j个节点，\(L(w)\)是p的长度，则\(n(w,1)=\mathrm{root}\)，\(n(w, L(w))=w\)。对于任何的内点n，我们令\(ch(n)\)为n的任何一个选定的子节点，不是一般性的我们可以令它为n的左子节点。令\([x]\)为1，如果x为真，否则为-1，那么我们可以根据如下公式定义\(p(w_O|w_I)\)：<br/>
\[<br/>
p(w|w_I) = \prod\limits_{j=1}^{L(w)-1}\sigma([n(w, j+1)=ch(n(w,j))]\cdot v_{n(w,j)}&#39;^T v_{w_I})<br/>
\]<br/>
我们下面证明：<br/>
引理1：\(\sum\limits_{w\in C} p(w|w_I) = 1\)<br/>
证明：<br/>
令T是C构成的Huffman二叉树，根据Huffman树的性质是我们可以令x和y为T中深度最深的两个兄弟，我们在T中去掉x和y，并且把它们的父亲节点命名为z，得到的新的词表称为\(C’\)(\(C’ = C - {x,y} + {z}\))，对应的完全二叉树命名为\(T’\)。我们下面证明：<br/>
\[<br/>
\sum\limits_{w\in C} p(w|w_I) = \sum\limits_{w\in C’} p’(w|w_I)\<br/>
\]<br/>
事实上：<br/>
\[<br/>
\begin{split}<br/>
\sum\limits_{w\in C} p(w|w_I) - \sum\limits_{w\in C’} p’(w|w_I) &amp;= p(x|w_I) +p(y|w_I) - p(z|w_I)\\<br/>
&amp;=\prod\limits_{j=1}^{L(x)-1}\sigma([n(x, j+1)=ch(n(x,j))]\cdot v_{n(x,j)}&#39;^T v_{w_I})\\<br/>
&amp;~~~~+\prod\limits_{j=1}^{L(y)-1}\sigma([n(y, j+1)=ch(n(y,j))]\cdot v_{n(y,j)}&#39;^T v_{w_I})\\<br/>
&amp;~~~~-\prod\limits_{j=1}^{L(z)-1}\sigma([n(z, j+1)=ch(n(z,j))]\cdot v_{n(z,j)}&#39;^T v_{w_I})\\<br/>
\end{split}<br/>
\]<br/>
显然有这些关系：<br/>
\[<br/>
\begin{align*}<br/>
L(x)=L(y)=L(z)+1\\<br/>
n(x,j) = n(y,j)=n(z,j), \forall 1\leq j\leq L(z)\\<br/>
\end{align*}<br/>
\]<br/>
因此<br/>
\[<br/>
\begin{split}<br/>
&amp;\sum\limits_{w\in C} p(w|w_I) - \sum\limits_{w\in C’} p’(w|w_I)\\<br/>
&amp;= \prod\limits_{j = 1}^{L(z)-1}\sigma([n(z,j+1)=ch(n(z,j))]\cdot v_{n(z,j)}&#39;^Tv_{w_I})\\<br/>
&amp;(\sigma([x=ch(n(z,L(z)))]v_{n(z,L(z))}&#39;^T v_{w_I}) + \sigma([y=ch(n(z, L(z)))]v_{n(z,L(z))}&#39;^T v_{w_I}) -1)\\<br/>
&amp;=0<br/>
\end{split}<br/>
\]<br/>
最后一个等式是因为：\(\sigma(x) + \sigma(-x) = 1, \forall x\in\mathbf{R}\)。</p>

<p>这样我们通过不断合并最深的两个兄弟节点，就可以最终把Huffman树合并成只有一个根的树，这样我们就证明了引理1的正确性。</p>

<hr/>

<p>根据引理1，我们通过（1）式定义的是一个概率测度。我们可以通过最最大似然法来进行参数估计。</p>

<p>这是一个测试。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Huffman树]]></title>
    <link href="https://sillybun.github.io/15540295441807.html"/>
    <updated>2019-03-31T18:52:24+08:00</updated>
    <id>https://sillybun.github.io/15540295441807.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">问题</h2>

<p>Huffman树是为了解决这样的问题：给一段文字，能不能给出一个编码方式使得这段文字长度最短。</p>

<h2 id="toc_1">思考</h2>

<p>比如对于<code>aabc</code>，如果我们a编码成00，b编码成01，c编码成10，那么这句话表示为：<code>00000110</code>，一共有8个比特。但是如果a编码成0，b编码成10，c编码成01，那么这句话表示为<code>001011</code>，一共有6个比特。<br/>
看到了么？不同的编码方式下同样的内容对应的长度是不相同的，如何得到一段文字的最佳编码方式呢？Huffman提供了一种算法，他提供了一个贪心的解决了编码问题，并且证明了这种贪心算法得到的答案是最优解。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_2">定义</h2>

<p>我们首先作出以下定义：<br/>
<strong>前缀编码</strong>：如果一个编码方式中没有一个编码是另一个编码的前缀，我们称这种编码方式为前缀编码。<br/>
我们可以看到，如果一种编码方式不是前缀编码，可能会出现二意性的问题，在使用上有很大的不方便。事实上，可以证明，最佳编码方式一定有一种是前缀编码，所以我们把我们的讨论范围限制在前缀编码上。<br/>
我们可以使用一颗二叉树来表示我们的编码方式，每个叶子结点代表一个字符，它的编码由根结点到它的唯一路径表示，如果是左子结点对应着编码0，如果是右子结点对应着编码0。这样的话对于深度为depth（这里认为根结点对应的深度为0）的字符它的编码长度为depth。在这棵二叉树上越浅的位置的字符拥有越少的编码长度。这样来看，我们应该把出现频率高的字符放置在二叉树比较浅的位置，出现频率低的字符放在二叉树比较深的位置。<br/>
显然，我们可以进一步的把我们的讨论范围局限在一颗完全二叉树上面来，这是因为，如果有一个结点只有1个子节点，我们完全可以把这个父亲结点取消掉，直接把子结点连接到父节点的父亲上。子树上的每个叶子结点对应的编码长度都会减少1。<br/>
这样的话，设一种编码方式对应的二叉树为T，对于字符集中的每一个字符c，我们令\(c.freq\)表示c出现的次数，\(d_T(c)\)表示c在树中的深度，这样需要编码这个文件的比特数为：<br/>
\[<br/>
B(T) = \sum\limits_{c\in C}c.freq \cdot d_T(c)<br/>
\]</p>

<h2 id="toc_3">Huffman树的建立</h2>

<p>我们作出以下约定：</p>

<ol>
<li>C表示字符集，里面含有n个字符，其中的每个字符c有一个属性\(c.freq\)</li>
<li>Q表示一个最小堆（优先级队列）<br/>
建立Huffman树的伪代码如下所示：</li>
</ol>

<pre class="line-numbers"><code class="language-python">Huffman(C)
N = |C|
Q = C
for i = 1 to n-1
    allocate a new node z
    z.left = x = Extract-Min(Q)
    z.right = y = Extract-Min(Q)
    z.freq = x.freq + y.freq
    Insert(Q, z)
return Extract-Min(Q)
</code></pre>

<h3 id="toc_4">时间复杂度分析</h3>

<p>建立最小堆的时间复杂度为\(O(n)\)，一共有n-1次循环，每一次循环的时间复杂度为\(O\log n\)，所以Huffman算法的时间复杂度为\(O(n\log n)\)</p>

<h2 id="toc_5">算法正确性的证明</h2>

<p>我们需要证明两个引理。</p>

<hr/>

<p>引理一：对于C中出现次数最低的两个字符x,y，一定存在着一种编码方式，使得x和y的编码长度一样，除了最后一位外其他的位置都相同。<br/>
证明：<br/>
我们只要证明在对应的二叉树上，x和y是兄弟结点就可以了。<br/>
对于一棵最优编码对应的二叉树T，设a和b是它深度最深的叶子兄弟（它们是叶子结点并且它们是兄弟）。假如a和b不是x和y，不妨假设x不是a也不是b。<br/>
我们对换x和a的位置，y和b的位置，得到了一棵新的二叉树\(T’\)<br/>
\[<br/>
\begin{split}B(T) - B(T’) &amp;= x.freq\cdot d_T(x) + a.freq\cdot d_T(a)-x.freq\cdot d_T(a) - a.freq\cdot d_T(x) + \dots \\<br/>
&amp;= (a.freq - x.freq) (d_T(a)-d_T(x)) +  (b.freq - y.freq) (d_T(b)-d_T(y))\\<br/>
&amp;\geq 0<br/>
\end{split}<br/>
\]<br/>
但是由于T是最佳二叉树，所以\(B(T) = B(T’)\)，所以\(T’\)也是完全二叉树，并且在\(T’\)中，x和y是最深的兄弟结点。<br/>
引理二：对于C中出现的次数最低的两个字符x,y，我们在C中去掉x和y，加入一个新的字符z，并且令\(z.freq=x.freq + y.freq\)，建立一个新的字符集\(C’\)。那么对于\(C’\)的最佳二叉树\(T’\)，我们把z对应的叶子结点去掉，放置一个内部结点，并且以x和y作为两个子节点对应的完全二叉树为C对应的一棵最佳二叉树。<br/>
证明：<br/>
我们首先说明\(B(T)\)和\(B(T’)\)之间的关系：\(d_{T’}(z) = d_T(x) + 1\)。<br/>
\[\begin{split}<br/>
B(T) - B(T’) &amp;= x.freq \cdot d_T(x) +y.freq \cdot d_T(y) - z.freq \cdot d_{T’}(z)\\<br/>
&amp;=x.freq \cdot d_T(x) +y.freq \cdot d_T(y) - (x.freq + y.freq) \cdot (d_{T}(x) - 1)\\<br/>
&amp;=x.freq + y.freq<br/>
\end{split}<br/>
\]<br/>
假设T不是C的一棵最佳二叉树，设\(T’’\)是C的一棵最佳二叉树，且根据引理1不妨假设x和y位于最深处并且x和y是兄弟。那么我们把x和y去掉并且把它们的父亲结点命名为z并且令\(z = x.freq + y.freq\)就构成了\(C’\)的一棵二叉树\(T’’’\)</p>

<p>\[\begin{split}<br/>
B(T’’’) &amp;= B(T’’) - x.freq - y.freq\\<br/>
&amp;&lt; B(T) - x.freq - y.freq\\<br/>
&amp;= B(T’) <br/>
\end{split}\]</p>

<p>这与\(T’\)是\(C’\)的最佳二叉树矛盾</p>

<hr/>

<p>根据引理一和引理二我们可以得到Huffman算法的正确性。</p>

]]></content>
  </entry>
  
</feed>

<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  信息论 - 张翼腾的博客
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="张翼腾的博客" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:sillybun.github.io ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="https://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; 张翼腾的博客</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        

    <li><label>Categories</label></li>

         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
  $(function(){
    $('#menu_item_index').addClass('is_active');
  });
</script>
<div class="row">
  <div class="large-8 medium-8 columns">
      <div class="markdown-body article-wrap">
       <div class="article">
          
          <h1>信息论</h1>
     
        <div class="read-more clearfix">
          <span class="date">2019/4/4</span>

          
           
         
          <span class="comments">
            

            
          </span>

        </div>
      </div><!-- article -->

      <div class="article-content">
      <h2 id="toc_0">熵</h2>

<p>假设离散随机变量X服从概率分布P。我们用它熵表示一个随机变量的不确定程度，用\(\mathbb{H} (X)\)或者是\(\mathbb{H}(p)\)表示：\[\mathbb{H}(X)\mathop{=}\limits^\Delta -\sum\limits_{k=1}^K p(X=k)\log p(X=k) = \mathop{E}\limits_{x\sim p(\cdot)}[\log(p(x))]\]</p>

<span id="more"></span><!-- more -->

<p>定理1: 在所有取值为\(\{1,2,\dots, K\}\)的离散随机变量，均匀分布取到最大熵。</p>

<p>这个定理的证明我会把它放到后面。根据这个定理我们可以得到Laplace&#39;s principle of insufficient reason. 当不能提供分布的任何信息的时候，我们偏好均匀分布，因为它保留了最大的不确定性。</p>

<h2 id="toc_1">KL divergence</h2>

<p>KL divergence（又称为相对熵），衡量了两种概率分布之间的不相似性：\[\mathbb{KL}(p\|q) = \sum_{k=1}^{K}p_k\log\frac{p_k}{q_k}=\mathop{\mathbb{E}}\limits_{x\sim  p(\cdot)}\log\frac{p(x)}{q(x)}\]</p>

<p>我们可以把KL divergence重新写为：\[\mathbb{KL}(p\|q) = \mathop{\mathbb{E}}\limits_{x\sim  p(\cdot)}\log p(x) - \mathop{\mathbb{E}}\limits_{x\sim p(\cdot)}\log {q(x)} = \mathbb{H}(p,q) - \mathbb{H}(p)\]</p>

<p>其中\[\mathbb{H}(p,q) = - \mathop{\mathbb{E}}\limits_{x\sim p(\cdot)}\log {q(x)}\]被称为交叉熵。</p>

<p>定理2：\(\mathbb{KL}(p,q) \geq 0\). 当且仅当\(p=q\)时相对熵等于0。</p>

<p>证明：<br/>
\[\begin{split}\mathbb{KL}(p,q) &amp;= \sum_{k=1}^{K}p_k\log\frac{p_k}{q_k}\\<br/>
&amp;= - \sum_{k=1}^{K}p_k\log\frac{q_k}{p_k}\\<br/>
&amp;\geq - \log \sum_{k=1}^{K}p_k\frac{q_k}{p_k}\\<br/>
&amp;= 0\\<br/>
\end{split}<br/>
\]</p>

<p>最后一个大于等于号是由于\(\log(\cdot)\)函数是concave函数。并且可以看到等号成立当且仅当存在c，使得\(p(x) = cq(x)\forall x\)，但是由于\(p(x)\)和\(q(x)\)都是自归一化的，所以\(c=1\)。</p>

<p>因此，\(\mathbb{KL}(p,q) =0\)当且仅当\(p=q\)。</p>

<p>我们使用这个定理来证明定理1。令\(p(x)\)是\(\{1,2,\dots,K\}\)上的概率函数，\(u(x)\)是其上的均匀分布。根据定理2,\[\begin{split}\mathbb{KL}(p\|u) &amp;=  \mathop{\mathbb{E}}\limits_{x\sim p(\cdot)} \log p(x) - \mathop{\mathbb{E}}\limits_{x\sim p(\cdot)} \log u(x)\\<br/>
&amp;= \mathop{\mathbb{E}}\limits_{x\sim p(\cdot)} \log p(x) + \mathop{\mathbb{E}}\limits_{x\sim u(\cdot)} \log u(x) \\&amp;= \mathbb{H}(u) - \mathbb{H}(p)\geq 0\end{split}\]</p>

<h2 id="toc_2">共同信息MI</h2>

<p>我们考虑两个随机变量X和Y我们来衡量两个随机变量之间的独立情况，我们可以用相关系数来衡量，但是相关性并不能完全的衡量独立性。为此我们引入共同信息（Mutual infromation or MI）。是这样定义的：\[\mathbb{I}(X;Y) \mathop{=}\limits^\Delta \mathbb{KL}(p(X,Y)\|P(X)p(Y)) = \sum\limits_x\sum\limits_y p(x,y)\log\frac{p(x,y)}{p(x)p(y)}\]</p>

<p>因此\(\mathbb{I}(X;Y)\geq 0\)。当且仅当X和Y独立时为0。</p>

<p>\[\begin{split}<br/>
\mathbb{I}(X;Y) &amp;= \sum\limits_x\sum\limits_y p(x,y)\log\frac{p(x,y)}{p(x)p(y)}\\<br/>
&amp;= \sum\limits_x\sum\limits_y p(x,y)[\log p(x|y) -  \log p(x)]\\<br/>
&amp;= \sum\limits_{y}p(y)\sum\limits_{x}p(x|y)\log p(x|y) - \sum_{x}p(x)\log p(x)\\<br/>
&amp;= - \sum\limits_{y}p(y)H(Y|X=x) + H(X)\\<br/>
&amp;= H(X) - H(X|Y)\\<br/>
\end{split}\]</p>

<p>逐点互信息\[\mathrm{PMI}(X,Y) \mathop{=}\limits^{\Delta} \log\frac{p(x,y)}{p(x)p(y)} = \log \frac{p(x|y)}{p(x)} = \log \frac{p(y|x)}{p(y)}\]，他刻画了当我们知道y后将\(p(x)\)更新为\(p(x|y)\)所能得到的信息量。</p>

<h2 id="toc_3">Cross entropy loss 与MLE</h2>

<p>在机器学习中一个常见的损失函数是Cross Entopy Loss。这里我们讨论一个多分类的问题，我们要把样本分到编号对应为\(1,2,\dots, n\)的类里面，我们的真实的编号是\(l_{true}\)，我们模型预测的属于某个编号的概率是\(P(l=k) = y_k\)，那么Cross Entropy Loss是：\[\mathrm{loss}_{CE}= -\log y_{l_{true}}\]</p>

<p>我们这里有两种解释，一种是基于Cross Entropy：真实的概率分布是\(P_{true}(l=k) = \delta(k, l_{true})\)，估计的概率分布为\(P_{pred}=y_k\)。那么我们用\(H(P_{true}, P_{pred}) = \mathbb{KL}(P_{true}\|P_{pred})\)，来刻画两者之间的差异程度。根据Cross Entropy的性质\(\mathrm{loss}_{\mathrm{CE}} \geq 0\)，并且当且仅当两者一致时为0。</p>

<p>另一种解释是基于MLE，似然函数就是是：\(y_{l_{true}}\)，所以对应的负对数释然函数就是：\[\ell = -\log y_{l_{true}}\]</p>

<p>因此在标签唯一的情况下，Cross Entropy Loss和MLE是一致的。</p>


    

      </div>

      <div class="row">
        <div class="large-6 columns">
        <p class="text-left" style="padding:15px 0px;">
      
          <a href="15546453666266.html" 
          title="Previous Post: 向量微分计算">&laquo; 向量微分计算</a>
      
        </p>
        </div>
        <div class="large-6 columns">
      <p class="text-right" style="padding:15px 0px;">
      
          <a  href="15541232015450.html" 
          title="Next Post: Noise Contrastive Estimation and Negative Sampling">Noise Contrastive Estimation and Negative Sampling &raquo;</a>
      
      </p>
        </div>
      </div>
      <div class="comments-wrap">
        <div class="share-comments">
          

          

          
        </div>
      </div>
    </div><!-- article-wrap -->
  </div><!-- large 8 -->




 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <h1>张翼腾的博客</h1>
                <div class="site-des">主要关注点在于自然语言处理领域，作者在学习的过程中分享自己学到的新的内</div>
                <div class="social">










<a target="_blank" class="email" href="mailto:15307130114@fudan.edu.cn" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15547144642483.html">矩阵微分计算</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15546453666266.html">向量微分计算</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15543921008119.html">信息论</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15541232015450.html">Noise Contrastive Estimation and Negative Sampling</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15540423884690.html">Word2Vec入门</a>
			      </li>
		     
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-137432635-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-137432635-1');
</script>


  </body>
</html>

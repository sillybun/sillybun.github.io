<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  张翼腾的博客
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="张翼腾的博客" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:sillybun.github.io ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="https://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; 张翼腾的博客</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        

    <li><label>Categories</label></li>

         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="15547144642483.html">
                
                  <h1>矩阵微分计算</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">符号表示</h2>

<p>若\(A\)和\(B\)都是\(n\times m\)的矩阵，那么：\(A\oplus B\)和\(A\otimes B\)都是\(n\times m\)的矩阵，它们第\((i,j)\)位置的元素值分别为：\(A_{i,j}+B_{i,j}\)和\(A_{i,j} \times B_{i,j}\)。</p>

<h2 id="toc_1">矩阵微分</h2>

<p>为了引入矩阵微分的概念，如果这时候涉及到数值/向量/矩阵对数值/向量/矩阵的求导，若分别定义的话太过繁琐，我们下面把数值和向量均看成矩阵，数值是\(1\times 1\)的矩阵，而维度为\(n\)的向量是维度为\(n\times 1\)的矩阵。这样我们只要定义好矩阵对矩阵的导数，就包含了全部的情况。不过这样做后要对数乘做特殊的处理：若\(a\)是一个数值，\(A\)是一个\(n\times m\)的矩阵，我们用\(I^a_n\)表示对角线元素全部为\(a\)的对角矩阵。</p>

<p>\[aA\mathop{=}\limits^{\Delta} I^a_n A\]</p>

<p>\[Aa\mathop{=}\limits^{\Delta}A I^a_m\]</p>

<p>下面定义矩阵对矩阵的微分：</p>

<p>设\(A\)，\(B\)分别为维度为\(n\times m\)， \(p\times q\)的矩阵，我们定义\(\frac{\partial A}{\partial B}\)为一个以\(q\times p\)维度的矩阵为元素的维度为\(n\times m\)的矩阵。我们把这样的矩阵的维度表示为：\(n\times m\to q\times p\)，把这样的矩阵叫做四维矩阵，用一个大写字母上面标4表示它为四维矩阵比如\(\mathop{A}\limits^4\)。其中的第\((i,j)\)位置元素为：</p>

<p>\[(\frac{\partial A}{\partial B})_{i,j} = \begin{bmatrix}<br/>
    \frac{\partial A_{i,j}}{\partial B_{1,1}} &amp; \frac{\partial A_{i,j}}{\partial B_{2,1}} &amp;  \dots  &amp; \frac{\partial A_{i,j}}{\partial B_{p,1}} \\<br/>
    \frac{\partial A_{i,j}}{\partial B_{1,2}} &amp; \frac{\partial A_{i,j}}{\partial B_{2,2}} &amp;  \dots  &amp; \frac{\partial A_{i,j}}{\partial B_{p,2}} \\<br/>
    \vdots &amp; \vdots &amp;  \ddots &amp; \vdots \\<br/>
    \frac{\partial A_{i,j}}{\partial B_{1,p}} &amp; \frac{\partial A_{i,j}}{\partial B_{2,p}} &amp;  \dots  &amp; \frac{\partial A_{i,j}}{\partial B_{q,p}}<br/>
\end{bmatrix}\]</p>

<h3 id="toc_2">运算规则</h3>

<p>我们下面来定义涉及到这种以矩阵为元素的矩阵的运算。</p>

<p>设\(\mathop{A}\limits^4\)，\(\mathop{B}\limits^4\)均为维度为\(n\times m\to p\times q\)的四维矩阵，那么：\(\mathop{A}\limits^4\pm \mathop{B}\limits^4\)是一个维度为\(n\times m\to p\times q\)的四维矩阵，其中的第\((i,j)\)位置的元素是\({\mathop{A}\limits^4}_{i,j}\pm {\mathop{B}\limits^4}_{i,j}\)。显然这样定义的加法和减法满足交换律、结合律。</p>

<p>数乘运算：设\(\mathop{A}\limits^4\)为维度为\(n\times m\to p\times q\)的四维矩阵，\(c\)是一个数，定义\(c\mathop{A}\limits^4 = (c{\mathop{A}\limits^4}_{i,j})_{n\times m\to p\times q}\)。数乘运算对四维矩阵加减法满足分配律。</p>

<!--
四维矩阵的迹：设$\mathop{A}\limits^4$为维度为$n\times n\to p\times q$的四维矩阵，那么它的迹是一个维度为$p\times q$的矩阵：$$\mathrm{tr}(\mathop{A}\limits^4) = \sum\limits_{i=1}^n {\mathop{A}\limits^4}_{i,i}$$
-->

<p>四维矩阵的转置：设\(\mathop{A}\limits^4\)为维度为\(m\times n\to p\times q\)的四维矩阵，那么它的转置\({\mathop{A^\top}\limits^4}\)是一个维度为\(n\times m\to p\times q\)的四维矩阵，且其第\((i,j)\)位置的元素为：\(A_{j,i}\)。则：\({\mathop{A^\top}\limits^4} {\mathop{B^\top}\limits^4} = ({\mathop{B}\limits^4} {\mathop{A}\limits^4})^\top\)</p>

<p>四维矩阵与二维矩阵之间的乘法：设\(\mathop{A}\limits^4\)为维度为\(n\times m\to p\times q\)的四维矩阵，\(B\)、\(C\)分别为维度为\(m\times r\)和\(s\times n\)的矩阵，那么：\(\mathop{A}\limits^4 B\)是一个维度为\(n\times r\to p\times q\)的四维矩阵，其中的第\((i,j)\)元素为：\((\mathop{A}\limits^4 B)_{i,j} = \sum\limits_{k=1}^m {\mathop{A}\limits^4}_{i,k}B_{k,j}\)；\(C \mathop{A}\limits^4\)是一个维度为\(s\times m\to p\times q\)的四维矩阵，其中的第\((i,j)\)元素为：\((C \mathop{A}\limits^4)_{i,j} = \sum\limits_{k=1}^n {C_{i,k} \mathop{A}\limits^4}_{k,j}\)。</p>

<p>四维矩阵与四维矩阵之间的乘法：设\(\mathop{A}\limits^4\)，\(\mathop{B}\limits^4\)分别为维度为\(n\times m\to p\times q\)和\(q\times p\to r\times s\)的四维矩阵，那么我们定义\(\mathop{A}\limits^4\mathop{B}\limits^4\)是一个\(n\times m\to r\times s\)的四维矩阵，其中的第\((i,j)\)个元素为：<br/>
\[(\mathop{A}\limits^4\mathop{B}\limits^4)_{i,j} = \mathrm{tr}({\mathop{A}\limits^4}_{i,j}\mathop{B}\limits^4) = \sum\limits_{k=1}^{p}\sum\limits_{l=1}^{q}(A_{i,j})_{k,l}B_{l,k}\]</p>

<p>我们可以用下列式子来帮助理解：</p>

<p>\[<br/>
\begin{matrix}<br/>
\mathop{A}\limits^4 &amp;B&amp;\longrightarrow &amp;\mathop{A}\limits^4 B\\<br/>
m\times k\to p\times q&amp;k\times n&amp;\longrightarrow&amp; m\times n\to p\times q\\<br/>
\end{matrix}<br/>
\]</p>

<p>\[<br/>
\begin{matrix}<br/>
C &amp; \mathop{A}\limits^4 &amp;\longrightarrow &amp; C \mathop{A}\limits^4\\<br/>
m\times k&amp; k\times n\to p\times q&amp;\longrightarrow&amp; m\times n\to p\times q\\<br/>
\end{matrix}<br/>
\]</p>

<p>\[<br/>
\begin{matrix}<br/>
\mathop{A}\limits^4 &amp; \mathop{B}\limits^4 &amp;\longrightarrow &amp;\mathop{A}\limits^4 \mathop{B}\limits^4\\<br/>
n\times m\to p\times q&amp; q\times p\to r\times s &amp;\longrightarrow&amp; n\times m\to r\times s\\<br/>
\end{matrix}<br/>
\]</p>

<p>这样的定义满足：</p>

<ol>
<li>结合律：\((\mathop{A}\limits^4 \mathop{B}\limits^4)\mathop{C}\limits^4 = \mathop{A}\limits^4 (\mathop{B}\limits^4 \mathop{C}\limits^4)\)，\((\mathop{A}\limits^4 B)C  = \mathop{A}\limits^4 (B C)\)，\((A \mathop{B}\limits^4)C = A (\mathop{B}\limits^4 C)\)，\((A B)\mathop{C}\limits^4 = A (B \mathop{C}\limits^4)\)，\((A \mathop{B}\limits^4)\mathop{C}\limits^4 = A(\mathop{B}\limits^4 \mathop{C}\limits^4)\)</li>
<li>分配律：\((\mathop{A}\limits^4 + \mathop{B}\limits^4) \mathop{C}\limits^4 = \mathop{A}\limits^4 \mathop{C}\limits^4 + \mathop{B}\limits^4 \mathop{C}\limits^4\)，\(\mathop{C}\limits^4 (\mathop{A}\limits^4 + \mathop{B}\limits^4)  = \mathop{C}\limits^4 \mathop{A}\limits^4 + \mathop{C}\limits^4 \mathop{B}\limits^4\)，\((\mathop{A}\limits^4 + \mathop{B}\limits^4) C = \mathop{A}\limits^4 C + \mathop{B}\limits^4 C\)，\(C (\mathop{A}\limits^4 + \mathop{B}\limits^4)  = C \mathop{A}\limits^4 + C \mathop{B}\limits^4\)，\((A + B) \mathop{C}\limits^4 = A \mathop{C}\limits^4 + B \mathop{C}\limits^4\)，\(\mathop{C}\limits^4 (A + B)  = \mathop{C}\limits^4 A + \mathop{C}\limits^4 B\)</li>
<li>\(c(\mathop{A}\limits^4 \mathop{B}\limits^4) = (c\mathop{A}\limits^4)\mathop{B}\limits^4 = \mathop{A}\limits^4(c\mathop{B}\limits^4)\)，\(c(A \mathop{B}\limits^4) = (cA)\mathop{B}\limits^4 = A(c\mathop{B}\limits^4)\)，\(c(\mathop{A}\limits^4 B) = (c\mathop{A}\limits^4)B = \mathop{A}\limits^4(cB)\)</li>
</ol>

<!-- 
，$(\mathop{A}\limits^4 \mathop{B}\limits^4)C  = \mathop{A}\limits^4 (\mathop{B}\limits^4 C)$，$(\mathop{A} \mathop{B}\limits^4)\mathop{C}\limits^4 = \mathop{A} (\mathop{B}\limits^4 \mathop{C}\limits^4)$，$(\mathop{A}\limits^4 B)\mathop{C}\limits^4 = \mathop{A}\limits^4 (B \mathop{C}\limits^4)$，$(\mathop{A}\limits^4 B)C  = \mathop{A}\limits^4 (B C)$，$(A \mathop{B}\limits^4)C = A (\mathop{B}\limits^4 C)$，$(A B)\mathop{C}\limits^4 = A (B \mathop{C}\limits^4)$
-->

<p>证明：<br/>
1）：<br/>
设\(\mathop{A}\limits^4\)、\(\mathop{B}\limits^4\)、\(\mathop{C}\limits^4\)的维度分别为\(n\times m\to q\times p\)、\(p\times q\to s\times r\)、\(r\times s\to v\times u\)<br/>
\[\begin{split}[(\mathop{A}\limits^4 \mathop{B}\limits^4)\mathop{C}\limits^4]_{i,j} &amp;= \sum\limits_{a = 1}^s\sum\limits_{b=1}^r ((\mathop{A}\limits^4 \mathop{B}\limits^4)_{i,j})_{a,b} C_{b,a}\\<br/>
&amp;= \sum\limits_{a = 1}^s\sum\limits_{b=1}^r (\sum\limits_{c=1}^q\sum\limits_{d=1}^p({\mathop{A}\limits^4}_{i,j})_{c,d}{\mathop{B}\limits^4}_{d,c})_{a,b} {\mathop{C}\limits^4}_{b,a}\\<br/>
&amp;= \sum\limits_{a = 1}^s\sum\limits_{b=1}^r \sum\limits_{c=1}^q\sum\limits_{d=1}^p({\mathop{A}\limits^4}_{i,j})_{c,d}({\mathop{B}\limits^4}_{d,c})_{a,b} {\mathop{C}\limits^4}_{b,a}\\<br/>
\end{split}\]</p>

<p>\[\begin{split}[\mathop{A}\limits^4 (\mathop{B}\limits^4\mathop{C}\limits^4)]_{i,j} &amp;= \sum\limits_{c = 1}^q\sum\limits_{d=1}^p ({\mathop{A}\limits^4}_{i,j})_{c,d}({\mathop{B}\limits^4}{\mathop{C}\limits^4})_{d,c}\\<br/>
&amp;= \sum\limits_{c = 1}^q\sum\limits_{d=1}^p ({\mathop{A}\limits^4}_{i,j})_{c,d} [\sum\limits_{a=1}^s\sum\limits_{b=1}^r ({\mathop{B}\limits^4}_{d,c})_{a,b}{\mathop{C}\limits^4}_{b,a}]\\<br/>
&amp;= \sum\limits_{c = 1}^q\sum\limits_{d=1}^p \sum\limits_{a=1}^s\sum\limits_{b=1}^r({\mathop{A}\limits^4}_{i,j})_{c,d}({\mathop{B}\limits^4}_{d,c})_{a,b} {\mathop{C}\limits^4}_{b,a}\\<br/>
&amp;= \sum\limits_{a = 1}^s\sum\limits_{b=1}^r \sum\limits_{c=1}^q\sum\limits_{d=1}^p({\mathop{A}\limits^4}_{i,j})_{c,d}({\mathop{B}\limits^4}_{d,c})_{a,b} {\mathop{C}\limits^4}_{b,a}\\<br/>
\end{split}\]</p>

<p>因此：\((\mathop{A}\limits^4 \mathop{B}\limits^4)\mathop{C}\limits^4 = \mathop{A}\limits^4 (\mathop{B}\limits^4 \mathop{C}\limits^4)\)</p>

<p>剩下的三个结论可以根据矩阵乘法的结合律直接得到。</p>

<p>对于最后一个结论：<br/>
设\(A\)是一个维度为\(n\times p\)的矩阵。</p>

<p>\[<br/>
\begin{split}<br/>
(A({\mathop{B}\limits^4}{\mathop{C}\limits^4}))_{i,j} &amp;= \sum_{k=1}^{p}A_{i,k}({\mathop{B}\limits^4}{\mathop{C}\limits^4})_{k,j}\\<br/>
&amp;= \sum_{k=1}^{p}A_{i,k}\mathrm{tr}({\mathop{B}\limits^4}_{k,j}{\mathop{C}\limits^4})\\<br/>
&amp;= \sum_{k=1}^{p}A_{i,k}\sum\limits_{a=1}^s\sum_{b=1}^r({\mathop{B}\limits^4}_{k,j})_{a,b}{\mathop{C}\limits^4}_{b,a}\\<br/>
&amp;= \sum\limits_{a=1}^s\sum_{b=1}^r \sum_{k=1}^{p}A_{i,k}({\mathop{B}\limits^4}_{k,j})_{a,b}{\mathop{C}\limits^4}_{b,a}\\<br/>
\end{split}<br/>
\]</p>

<p>\[<br/>
\begin{split}<br/>
((A{\mathop{B}\limits^4}){\mathop{C}\limits^4})_{i,j} &amp;= \mathrm{tr}((A{\mathop{B}\limits^4})_{i,j}{\mathop{C}\limits^4})\\<br/>
&amp;= \sum\limits_{a=1}^s\sum_{b=1}^r((A{\mathop{B}\limits^4})_{i,j})_{a,b}{\mathop{C}\limits^4}_{b,a}\\<br/>
&amp;= \sum\limits_{a=1}^s\sum_{b=1}^r(\sum_{k=1}^{p}A_{i,k}{\mathop{B}\limits^4}_{k,j})_{a,b}{\mathop{C}\limits^4}_{b,a}\\<br/>
&amp;=\sum_{k=1}^{p} \sum\limits_{a=1}^s\sum_{b=1}^r A_{i,k}({\mathop{B}\limits^4}_{k,j})_{a,b}{\mathop{C}\limits^4}_{b,a}\\<br/>
&amp;= \sum\limits_{a=1}^s\sum_{b=1}^r \sum_{k=1}^{p}A_{i,k}({\mathop{B}\limits^4}_{k,j})_{a,b}{\mathop{C}\limits^4}_{b,a}\\<br/>
&amp;= (A({\mathop{B}\limits^4}{\mathop{C}\limits^4}))_{i,j}\\<br/>
\end{split}<br/>
\]</p>

<p>2）我们只证明前两条：<br/>
设\(\mathop{A}\limits^4\)、\(\mathop{B}\limits^4\)、\(\mathop{C}\limits^4\)、\(\mathop{D}\limits^4\)的维度分别为\(n\times m\to q\times p\)、\(n\times m\to q\times p\)、\(p\times q\to s\times r\)、\(r\times s\to m\times n\)<br/>
\[<br/>
\begin{split}<br/>
[(\mathop{A}\limits^4 + \mathop{B}\limits^4) \mathop{C}\limits^4]_{i,j} &amp;= \sum_{a=1}^{q}\sum_{b=1}^p [(\mathop{A}\limits^4 + \mathop{B}\limits^4)_{i,j}]_{a,b}{\mathop{C}\limits^4}_{b,a}\\<br/>
&amp;= \sum_{a=1}^{q}\sum_{b=1}^p [({\mathop{A}\limits^4}_{i,j})_{a,b} + ({\mathop{B}\limits^4}_{i,j})_{a,b}]{\mathop{C}\limits^4}_{b,a}\\<br/>
&amp;= \sum_{a=1}^{q}\sum_{b=1}^p ({\mathop{A}\limits^4}_{i,j})_{a,b}{\mathop{C}\limits^4}_{b,a} + \sum_{a=1}^{q}\sum_{b=1}^p ({\mathop{B}\limits^4}_{i,j})_{a,b}{\mathop{C}\limits^4}_{b,a}\\<br/>
&amp;= (\mathop{A}\limits^4 \mathop{C}\limits^4)_{i,j} + (\mathop{B}\limits^4 \mathop{C}\limits^4)_{i,j}\\<br/>
\end{split}<br/>
\]</p>

<p>\[<br/>
\begin{split}<br/>
[\mathop{D}\limits^4(\mathop{A}\limits^4 + \mathop{B}\limits^4) ]_{i,j} &amp;= \sum_{a=1}^{n}\sum_{b=1}^m ({\mathop{D}\limits^4}_{i,j})_{a,b}(\mathop{A}\limits^4 + \mathop{B}\limits^4)_{b,a}\\<br/>
&amp;= \sum_{a=1}^{n}\sum_{b=1}^m ({\mathop{D}\limits^4}_{i,j})_{a,b}({\mathop{A}\limits^4}_{b,a} + {\mathop{B}\limits^4}_{b,a})\\<br/>
&amp;= \sum_{a=1}^{n}\sum_{b=1}^m [({\mathop{D}\limits^4}_{i,j})_{a,b}{\mathop{A}\limits^4}_{b,a} + ({\mathop{D}\limits^4}_{i,j})_{a,b}{\mathop{B}\limits^4}_{b,a}]\\<br/>
&amp;= \sum_{a=1}^{n}\sum_{b=1}^m ({\mathop{D}\limits^4}_{i,j})_{a,b}{\mathop{A}\limits^4}_{b,a} + \sum_{a=1}^{n}\sum_{b=1}^m({\mathop{D}\limits^4}_{i,j})_{a,b}{\mathop{B}\limits^4}_{b,a}\\<br/>
&amp;= (\mathop{D}\limits^4\mathop{A}\limits^4)_{i,j} + (\mathop{D}\limits^4 \mathop{B}\limits^4) _{i,j} \\<br/>
\end{split}<br/>
\]</p>

<!--
再设$C$为$m\times u$的矩阵，

$$
\begin{split}
[(\mathop{A}\limits^4 \mathop{B}\limits^4)C]_{i,j} &= \sum_{k=1}^{m}(\mathop{A}\limits^4 \mathop{B}\limits^4)_{i,k}C_{k, j}\\
&= \sum_{k=1}^{m}(\sum\limits_{a=1}^{q}\sum\limits_{b=1}^{p}({\mathop{A}\limits^4}_{i,j})_{a,b} {\mathop{B}\limits^4}_{b,a})C_{k, j}\\
&= \sum_{k=1}^{m}\sum\limits_{a=1}^{q}\sum\limits_{b=1}^{p}({\mathop{A}\limits^4}_{i,j})_{a,b} {\mathop{B}\limits^4}_{b,a}C_{k, j}\\
\end{split}
$$

$$
\begin{split}
[\mathop{A}\limits^4 (\mathop{B}\limits^4 C)]_{i,j} &= \sum_{k=1}^{m}(\mathop{A}\limits^4 \mathop{B}\limits^4)_{i,k}C_{k, j}\\
&= \sum_{k=1}^{m}(\sum\limits_{a=1}^{q}\sum\limits_{b=1}^{p}({\mathop{A}\limits^4}_{i,j})_{a,b} {\mathop{B}\limits^4}_{b,a})C_{k, j}\\
&= \sum_{k=1}^{m}\sum\limits_{a=1}^{q}\sum\limits_{b=1}^{p}({\mathop{A}\limits^4}_{i,j})_{a,b} {\mathop{B}\limits^4}_{b,a}C_{k, j}\\
\end{split}
$$

-->

<!--

我们定义了四种矩阵微分：

第一种是矩阵对向量的微分：

令$A = \varphi(x)$其中$x$是一个$l$维的向量，$A$是一个$n\times m$的矩阵，我们定义：$\frac{\partial A}{\partial x}$是一个张量矩阵，我们用大写字母上面标1（比如$\mathop{A}\limits^1$）表示一个矩阵是张量矩阵，也就是说，是一个$n\times m$的矩阵，其中的每个元素是一个$l$维向量的转置：

$$(\frac{\partial A}{\partial x})_{i,j} = \frac{\partial  A_{i,j}}{\partial x}$$

$$\frac{\partial A}{\partial x} = \begin{bmatrix}
    \frac{\partial A_{1,1}}{\partial x} & \frac{\partial A_{1,2}}{\partial x_2} &  \dots  & \frac{\partial A_{1,n}}{\partial x_n} \\
    \frac{\partial y_2}{\partial x_1} & \frac{\partial y_2}{\partial x_2} &  \dots  & \frac{\partial y_2}{\partial x_n} \\
    \vdots & \vdots &  \ddots & \vdots \\
    \frac{\partial y_m}{\partial x_1} & \frac{\partial y_m}{\partial x_n} &  \dots  & \frac{\partial y_m}{\partial x_n}
\end{bmatrix}$$

我们用$n\times m\to l$表示上述张量矩阵的维度。

我们定义张量矩阵的加法是平凡的：对于维度相同的张量矩阵，它们的加法是同样维度的张量矩阵，每个位置的元素值是原来两个矩阵对应位置元素的求和。

同时我们要定义这种矩阵的乘法：

对于一个$n\times m\to l$维的张量矩阵$\mathop{A}\limits^1$：

- 若$a$是一个数值，$a\mathop{A}\limits^1 = \mathop{A}\limits^1 a$是一个张量矩阵，其中的第$(i,j)$个元素是原张量矩阵第$(i,j)$个元素的$a$倍。
- 若$z$是一个$m$维的向量，$\mathop{A}\limits^1 \cdot z$是一个$n\times l$的矩阵，其中的第$(i,k)$位置的元素为：$\sum\limits_{j=1}^{m}(\mathop{A}\limits^1)_{i,j} z_j$。
- 若$B$是一个$m\times p$的矩阵，$\mathop{A}\limits^1 \cdot B$是一个$n\times p\to l$维的张量矩阵，其中的第$(i,k)$位置的元素是一个向量的转置：$(\mathop{A}\limits^1\cdot B)_{i,k} = \sum\limits_{j=1}^{m}(\mathop{A}\limits^1)_{i,j} B_{j,k}$。

第二种是数值对矩阵的微分：

$\alpha = f(A)$，其中$A$是一个$m\times n$的矩阵，$\alpha$是一个数值，那么：$$\frac{\partial \alpha}{\partial A} = \begin{bmatrix}
    \frac{\partial \alpha}{\partial A_{1,1}} & \frac{\partial \alpha}{\partial A_{2,1}} &  \dots  & \frac{\partial \alpha}{\partial A_{m,1}} \\
    \frac{\partial \alpha}{\partial A_{1,2}} & \frac{\partial \alpha}{\partial A_{2,2}} &  \dots  & \frac{\partial \alpha}{\partial A_{m,2}} \\
    \vdots & \vdots &  \ddots & \vdots \\
    \frac{\partial \alpha}{\partial A_{1,n}} & \frac{\partial \alpha}{\partial A_{2,n}} &  \dots  & \frac{\partial \alpha}{\partial A_{m,n}}
\end{bmatrix}$$

这样：$\frac{\partial \alpha}{\partial A} = \sum\limits_{i=1}^{n}\sum\limits_{j=1}^{m}\frac{\partial \alpha}{\partial A_{i,j}}e_{j,i}$

第三种是向量对矩阵的微分：

设$x = f(A)$，其中$x$是一个$l$维的向量，$A$是一个$n\times m$的矩阵，$\frac{\partial x}{\partial A}$是一个矩阵向量：它是一个$l$维向量，每一个元素是一个$m\times n$的矩阵，它的第$i$个元素是$\frac{\partial x_i}{\partial A}$。它的维度定义为：$l\to m\times n$，用小写字母上面加上2来表示（比如$\mathop{x}\limits^2$）。

$$
\frac{\partial x}{\partial A} = \begin{bmatrix}\frac{\partial x_1}{\partial A}\\
\frac{\partial x_2}{\partial A}\\
\vdots\\
\frac{\partial x_l}{\partial A}\\
\end{bmatrix}
$$

我们需要定义矩阵向量的乘法：
设$\mathop{x}\limits^{2}$是一个$l\to m\times n$的矩阵向量。

- 若$a$是一个数值，$a\mathop{x}\limits^2 = \mathop{x}\limits^2 a$是一个向量矩阵，其中的第$i$个元素是原张量矩阵第$i$个元素的$a$倍。
- 若$z$是一个$l$维的向量，$\mathop{x}\limits^2 \cdot z^\top$是一个$l\times l$的矩阵矩阵（维度为：$l\times l\to m\times n$），其中的第$(i,j)$位置的元素为：$ (\mathop{x}\limits^{2})_i z_j$。$z^\top \mathop{x}\limits^2 \cdot$是一个矩阵：$\sum\limits_{i=1}^l (\mathop{x}\limits^{2})_i z_i$
- 若$A$是一个$p\times l$的矩阵，$A \cdot \mathop{x}\limits^2$是一个$p\to m\times n$维的矩阵向量，其中的第$i$位置的元素是一个矩阵：$(A \cdot \mathop{x}\limits^2)_i = \sum\limits_{j=1}^{l}A_{i,j}(\mathop{x}\limits^{2})_j$；

最后：矩阵对矩阵的微分：

$Y = f(A)$，其中$A$是一个$n\times m$的矩阵，$Y$是一个$p\times q$的矩阵，那么：$\frac{\partial Y}{\partial A}$是一个四维的结构，我们可以把它看成一个$p\times q$的矩阵，只是其中的第$(i,j)$个元素是一个矩阵：$\frac{\partial Y_{i,j}}{\partial A}$。我们叫它矩阵矩阵（用一个大写字母上面标2表示比如$\mathop{A}\limits^2$），定义它的维度为：$p\times q\to m\times n$。

矩阵矩阵和普通矩阵的乘法和一般矩阵的乘法定义是一样的，只是要注意的是有的元素可能是一个矩阵。
对于一个$p\times q\to m\times n$维的张量矩阵$\mathop{A}\limits^2$：

- 若$a$是一个数值，$a\mathop{A}\limits^2 = \mathop{A}\limits^2 a$是一个矩阵矩阵，其中的第$(i,j)$个元素是原矩阵矩阵第$(i,j)$个元素的$a$倍。
- 若$z$是一个$q$维的向量，$\mathop{A}\limits^2 \cdot z$是一个$p\to m\times n$的矩阵向量，其中的第$i$位置的元素为：$\sum\limits_{j=1}^{q}(\mathop{A}\limits^2)_{i,j} z_j$。
- 若$B$是一个$q\times r$的矩阵，$\mathop{A}\limits^2 \cdot B$是一个$p\times r\to m\times n$维的矩阵矩阵，其中的第$(i,k)$位置的元素是一个矩阵：$(\mathop{A}\limits^2\cdot B)_{i,k} = \sum\limits_{j=1}^{q}(\mathop{A}\limits^2)_{i,j} B_{j,k}$；若$C$是一个$r\times p$的矩阵，$C\cdot \mathop{A}\limits^2$是一个$r\times q\to m\times n$维的矩阵矩阵，其中的第$(i,k)$位置的元素是一个矩阵：$(C\cdot \mathop{A}\limits^2)_{i,k} = \sum\limits_{j=1}^{p}C_{i,j}(\mathop{A}\limits^2)_{j,k} $。
- 若$\mathop{B}\limits^2$是一个维度为$n\times m \to s\times r$的矩阵矩阵，那么$\mathop{A}\limits^2 \mathop{B}\limits^2$是一个维度为$p\times q\to s\times r$的矩阵矩阵，其中的第$(i,j)$个元素为$\mathrm{tr} [(\mathop{A}\limits^2)_{i,j} \mathop{B}\limits^2]$

 > 注意：这种定义的数值对矩阵的微分和我们定义的向量微分是不一致的，如果把向量当成一个一列的矩阵的话，数值对向量的微分应该是一个列向量，但是我们实际上数值对向量的微分是一个向量的转置。
-->

<h2 id="toc_3">命题</h2>

<p>命题1：\(y = f(A)\)是一个数值，\(\mathrm{d}y = \mathrm{tr}((\frac{\partial y}{\partial A})_{1,1}\mathrm{d}A)\)。其中\(\mathrm{d}A = (\mathrm{d}A_{i,j})_{i=1,2,\dots,m\colon j = 1,2,\dots, n}\)</p>

<p>证明：<br/>
\(\mathrm{d}y = \sum\limits_{i=1}^n \sum\limits_{j=1}^m \frac{\partial y}{\partial A_{i,j}}\mathrm{d}A_{i,j} = \mathrm{tr}((\frac{\partial y}{\partial A})_{1,1}\mathrm{d}A)\)</p>

<p>命题2：\(A = f(B)\)，\(B=g(C)\)，\(A\),\(B\)，\(C\)分别为\(m\times n\)、\(p\times q\)、\(r\times s\)的矩阵，那么：\(\frac{\partial A}{\partial B} =\frac{\partial A}{\partial B} \frac{\partial B}{\partial C}\)</p>

<p>证明：<br/>
\[\begin{split}(\frac{\partial A}{\partial C})_{i,j} &amp;= \frac{\partial A_{i,j}}{\partial C}\\<br/>
&amp;= \sum_{a=1}^p\sum_{b=1}^q \frac{\partial A_{i,j}}{\partial B_{a,b}}\frac{\partial B_{a,b}}{\partial C}\\<br/>
&amp;= \sum_{a=1}^p\sum_{b=1}^q \frac{\partial A_{i,j}}{\partial B_{a,b}}\frac{\partial B_{a,b}}{\partial C}\\<br/>
&amp;= \mathrm{tr} [(\frac{\partial A}{\partial B})_{i,j} \frac{\partial B}{\partial C}]\\<br/>
&amp;= (\frac{\partial A}{\partial B} \frac{\partial B}{\partial C})_{i,j}<br/>
\end{split}\]</p>

<!--

$\frac{\partial y}{\partial A} = \begin{bmatrix}\frac{\partial y}{\partial A_{1,1}} & \frac{\partial y}{\partial A_{2,1}} & \dots & \frac{\partial y}{\partial A_{n, 1}}\\\frac{\partial y}{\partial A_{1,2}} & \frac{\partial y}{\partial A_{2,2}}& \dots & \frac{\partial y}{\partial A_{n, 2}}\\ \vdots & \vdots & \ddots & \vdots\\\frac{\partial y}{\partial A_{1,m}} & \frac{\partial y}{\partial A_{2,m}}& \dots & \frac{\partial y}{\partial A_{n, m}}\end{bmatrix}$

$\frac{\partial A}{\partial B} = \begin{bmatrix}\frac{\partial A_{1,1}}{\partial B} & \frac{\partial A_{1,2}}{\partial B} & \dots & \frac{\partial A_{1,m}}{\partial B}\\\frac{\partial A_{2,1}}{\partial B} & \frac{\partial A_{2,2}}{\partial B}& \dots & \frac{\partial A_{2,m}}{\partial B}\\ \vdots & \vdots & \ddots & \vdots\\\frac{\partial A_{n,1}}{\partial B} & \frac{\partial A_{n,2}}{\partial B}& \dots & \frac{\partial A_{n,m}}{\partial B}\end{bmatrix}$

$\mathrm{tr}(\frac{\partial y}{\partial A} \frac{\partial A}{\partial B}) = \sum\limits_{i=1}^{n}\sum\limits_{j=1}^m\frac{\partial y}{\partial x_{i,j}}\frac{\partial x_{i,j}}{\partial B} = \frac{\partial y}{\partial B}$



命题3：$a = f(A)$，$b = g(A)$，A是$n\times m$维的矩阵，$a,b\in\mathbb{R}$，那么：$\frac{\partial (ab)}{\partial A} = a\frac{\partial b}{\partial A} + b\frac{\partial a}{\partial A}$，$\frac{\partial (a+b)}{\partial A} = \frac{\partial a}{\partial A} + \frac{\partial b}{\partial A}$

-->

<p>命题3：若\(A\)，\(B\)，\(C\)分别为\(n\times m\)、\(m\times p \)和\(r\times s\)的矩阵，那么\(\frac{\partial (A+B)}{\partial C}=\frac{\partial A}{\partial C} + \frac{\partial B}{\partial C}\)， \(\frac{\partial (AB)}{\partial C} = \frac{\partial A}{\partial C}B + A\frac{\partial B}{\partial C}\)。</p>

<p>证明：</p>

<p>\[\begin{split}<br/>
[\frac{\partial (AB)}{\partial C})_{i,j}]_{k,l} &amp;= \frac{\partial (AB)_{i,k}}{\partial  C_{k,l}}\\<br/>
&amp;= \frac{\partial \sum\limits_{a=1}^{m} A_{i,a}B_{a, j}}{\partial  C_{k,l}}\\<br/>
&amp;= \sum\limits_{a=1}^{m}[\frac{\partial A_{i, a}}{\partial C_{k,l}}B_{a,j} + A_{i, a}\frac{\partial B_{a, j}}{\partial C_{k,l}}]\\<br/>
&amp;= \sum\limits_{a=1}^{m}\frac{\partial A_{i, a}}{\partial C_{k,l}}B_{a,j} + \sum\limits_{a=1}^{m} A_{i, a}\frac{\partial B_{a, j}}{\partial C_{k,l}}\\<br/>
&amp;= \sum\limits_{a=1}^{m}[(\frac{\partial A}{\partial C})_{i,a}]_{k,l}B_{a,j} + \sum\limits_{a=1}^{m} A_{i, a}[(\frac{\partial B}{\partial C})_{a, j}]_{k,l}\\<br/>
&amp;= \sum\limits_{a=1}^{m}[(\frac{\partial A}{\partial C})_{i,a}]_{k,l}B_{a,j} + \sum\limits_{a=1}^{m} A_{i, a}[(\frac{\partial B}{\partial C})_{a, j}]_{k,l}\\<br/>
\end{split}<br/>
\]</p>

<p>命题5：\(A = f(B)\)，\(B=g(C)\)，其中\(A\)，\(B\)，\(C\)分别为\(n\times m\)、\(p\times q \)和\(r\times s\)的矩阵。那么\(\frac{\partial A}{\partial C} = \frac{\partial A}{\partial B}\frac{\partial B}{\partial C}\)</p>

<p>证明：<br/>
\[\begin{split}(\frac{\partial A}{\partial C})_{i,j} &amp;= \frac{\partial A_{i,j}}{\partial  C}\\<br/>
&amp;= \mathrm{tr}(\frac{\partial A_{i,j}}{\partial B}\frac{\partial B}{\partial C})\\<br/>
&amp;= (\frac{\partial A}{\partial B}\frac{\partial B}{\partial C})_{i,j}<br/>
\end{split}\]</p>

<p>命题6：若\(f\colon \mathbb{R}\to \mathbb{R}\)，\[f(A)\mathop{=}\limits^\Delta \begin{bmatrix}<br/>
    f(A_{11}) &amp; f(A_{12}) &amp; \dots  &amp; f(A_{1n}) \\<br/>
    f(A_{21}) &amp; f(A_{22}) &amp; \dots  &amp; f(A_{2n}) \\<br/>
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br/>
    f(A_{n1}) &amp; f(A_{n2}) &amp; \dots  &amp; f(A_{mn})<br/>
\end{bmatrix}\]，那么\(\frac{\partial f(A)}{\partial B} = f&#39;(A)\otimes \frac{\partial A}{\partial B}\)。</p>

<p>证明：<br/>
\(\frac{\partial f(A_{i,j})}{\partial B} = f&#39;(A_{i,j})\frac{\partial A_{i,j}}{\partial B}\)</p>

<p>命题7：若\(X\)是一个\(n\times m\)维的矩阵，\(\frac{\partial X}{\partial X}\)是一个\(n\times m\to m\times n\)的矩阵矩阵，并且其第\((i,j)\)个元素是\(e_{j,i}\)，它是一个\(m\times n\)的矩阵，除第\((j,i)\)个元素为1外其余元素都为0。我们把这个矩阵命名为\(E_{n\times m}\)，它在我们矩阵求导中有非常重要的作用。</p>

<p>命题8：若\({\mathop{A}\limits^4}\)是一个维度为\(m\times n\to q\times p\)的四维矩阵，那么：\({\mathop{A}\limits^4} E_{p\times q} = E_{n\times m} {\mathop{A}\limits^4} = {\mathop{A}\limits^4}\)</p>

<p>证明：</p>

<p>命题9：若\(A\)是一个维度为\(m\times n\)的矩阵，\(B\)是一个\(p\times q\)的矩阵，我们定义：\(A\times B \mathop{=}\limits^\Delta AE_{n,p}B\)，它是一个维度为：\(m\times q\to p\times n\)的四维矩阵，其中第\((i,j)\)个元素为：\(Be_{ji}A\)</p>

<p>证明：</p>

<p>\[<br/>
\begin{split}<br/>
(A\times B)_{i,j} &amp;= (AE_{n,p}B)_{i,j}\\<br/>
&amp;= \sum_{a=1}^n\sum_{b=1}^p A_{i,a}e_{b,a}B_{b,j}\\<br/>
&amp;= Be_{j,i}A\\<br/>
\end{split}<br/>
\]</p>

<p>命题9推论：若\(a\)是一个\(n\)维的向量，\(b\)是一个\(m\)维的向量，那么\(a^\top E_{n, m}b = b a^\top\)。</p>

<p>命题10：若\(a\)、\(b\)、\(c\)都是\(n\)维的向量，那么：\(a^\top (b\otimes c) = (a\otimes b)^\top c = (a\otimes c)^\top b\)，在其中有一个是矩阵向量时也是正确的。</p>

<h2 id="toc_4">例子：</h2>

<p>例1：Cross Entropy Loss：\(\ell = -y^\top \log \frac{\exp(Wx)}{\mathbb{1}^\top \exp(Wx)}\)，求\(\frac{\partial \ell}{\partial W}\)</p>

<p>解：<br/>
\(\ell = -y^\top \log\exp(Wx) + \log[1^T\exp(Wx)] = -y^\top Wx + \log[1^\top\exp(Wx)]\)<br/>
\[\begin{split}<br/>
\frac{\partial \ell}{\partial W} &amp;= - x y^\top + \frac{1^\top[\exp(Wx)\otimes (\frac{\partial W}{\partial W}x)]}{1^\top \exp(Wx)}\\<br/>
&amp;= - x y^\top + \frac{[1\otimes \exp(Wx)]^\top(\frac{\partial W}{\partial W}x)}{1^\top \exp(Wx)}\\<br/>
&amp;= - x y^\top + \frac{x\exp(Wx)^\top}{1^\top \exp(Wx)}\\<br/>
&amp;= x(\mathrm{softmax}(Wx) - y)^\top<br/>
\end{split}\]</p>

<p>\(\ell = -y^\top \mathrm{softmax}(W_1\sigma(W_2X+b_2)+b_1)\)，求\(\frac{\partial \ell}{\partial W}\)</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/4/8</span>
                    
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15546453666266.html">
                
                  <h1>向量微分计算</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>矩阵微分在神经网络中的应用及其广泛，这里总结了各种矩阵微分的处理方法。</p>

<h2 id="toc_0">符号表示</h2>

<p><strong>矩阵</strong>: \(a_{i,j}\in\mathbb{R}\quad i=1,2,\dots, m;j=1,2,\dots m\)\[A = \begin{bmatrix}<br/>
    a_{11} &amp; a_{12} &amp; a_{13} &amp; \dots  &amp; a_{1n} \\<br/>
    a_{21} &amp; a_{22} &amp; a_{23} &amp; \dots  &amp; a_{2n} \\<br/>
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br/>
    a_{m1} &amp; a_{m2} &amp; a_{m3} &amp; \dots  &amp; a_{mn}<br/>
\end{bmatrix}\]是一个\(m\times n\)的矩阵。</p>

<p><strong>向量</strong>：一个\(n\)维的向量是一个\(n\times 1\)的矩阵，也就是说所有的向量都是列向量。</p>

<p>定义：若\(x\)是一个\(n\)维向量，\[\mathrm{diag}(x) = \begin{bmatrix}<br/>
    x_1 &amp; 0 &amp; 0 &amp; \dots  &amp; 0 \\<br/>
    0 &amp; x_2 &amp; 0 &amp; \dots  &amp; 0 \\<br/>
    0 &amp; 0 &amp; x_3 &amp; \dots  &amp; 0 \\<br/>
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br/>
    0 &amp; 0 &amp; 0 &amp; \dots  &amp; x_n<br/>
\end{bmatrix}\]</p>

<p>定义：若\(x\)是一个\(n\)维向量，\(y\)是一个\(n\)维向量，\[\begin{split}x\otimes y &amp;= [x_1y_1, x_2y_2,\dots, x_ny_n]^\top\\x\oplus y &amp;= [x_1+y_1, x_2+y_2,\dots, x_n+y_n]^\top\\\end{split}\]</p>

<h3 id="toc_1">向量微分</h3>

<p>令\(y=\phi(x)\)，其中\(y\)是一个\(m\)维的向量，\(x\)是一个\(n\)维的向量，我们定义：\[\frac{\partial y}{\partial x} \mathop{=}\limits^\Delta \begin{bmatrix}<br/>
    \frac{\partial y_1}{\partial x_1} &amp; \frac{\partial y_1}{\partial x_2} &amp;  \dots  &amp; \frac{\partial y_1}{\partial x_n} \\<br/>
    \frac{\partial y_2}{\partial x_1} &amp; \frac{\partial y_2}{\partial x_2} &amp;  \dots  &amp; \frac{\partial y_2}{\partial x_n} \\<br/>
    \vdots &amp; \vdots &amp;  \ddots &amp; \vdots \\<br/>
    \frac{\partial y_m}{\partial x_1} &amp; \frac{\partial y_m}{\partial x_n} &amp;  \dots  &amp; \frac{\partial y_m}{\partial x_n}<br/>
\end{bmatrix}\]</p>

<p>注意到如果\(x\)是一个数值，那么\(\frac{\partial y}{\partial x}\)是一个向量；如果\(y\)是一个数值，那么\(\frac{\partial y}{\partial x}\)是一个向量的转置。</p>

<blockquote>
<p>这样定义向量微分的原因是这种定义下有：\(\mathrm{d}y = \frac{\partial y}{\partial x}\mathrm{d}x\)。</p>
</blockquote>

<h2 id="toc_2">命题 -- 向量微分</h2>

<p>定理1：（线性性）若\(a,b\in\mathbb{R}\)，\(x\)是一个\(n\)维的向量，\(\phi\colon \mathbb{R}^n\to \mathbb{R}^m\)，\(\varphi\colon \mathbb{R}^n\to \mathbb{R}^m\)，那么\(\frac{\partial (a\phi(x)+ b\varphi(x))}{\partial x} = a\frac{\partial \phi(x)}{\partial x} + b\frac{\partial \varphi(x)}{\partial x}\)</p>

<p>定理2：（链锁法则）若\(y = \phi(z)\)，\(z = \varphi(x)\)，其中\(y\)是一个\(m\)维的向量，\(x\)是一个\(n\)维的向量，\(z\)是一个\(l\)维的向量，那么：\(\frac{\partial y}{\partial x} = \frac{\partial y}{\partial z}\frac{\partial z}{\partial x}\)</p>

<p>证明：<br/>
\(\frac{\partial y_i}{\partial z_k} = \sum_{j=1}^{n}\frac{\partial y_i}{\partial x_j}\frac{\partial x_j}{\partial z_k}\)<br/>
因此：\(\frac{\partial y}{\partial x} = \frac{\partial y}{\partial z}\frac{\partial z}{\partial x}\)</p>

<p>命题1：若\(y=Ax\)，其中\(y\)是一个\(m\)维的向量，\(x\)是一个\(n\)维的向量，\(A\)与\(x\)无关，那么：\(\frac{\partial y}{\partial x} = A\)。</p>

<p>证明：<br/>
\(y_i = \sum\limits_{k=1}^n A_{i,k}x_k\)<br/>
\(\frac{\partial y_i}{\partial x_j} = A_{i,j}\)<br/>
因此：\(\frac{\partial y}{\partial x} = A\)</p>

<p>命题2：若\(y=Ax\)，其中\(y\)是一个\(m\)维的向量，\(x\)是一个\(n\)维的向量，\(z\)是一个\(l\)维的向量，\(A\)与\(z\)无关，\(x\)是\(z\)的函数，那么\(\frac{\partial y}{\partial z} = A\frac{\partial x}{\partial z}\)。</p>

<p>证明：<br/>
\(y_i = \sum\limits_{k=1}^n A_{i,k}x_k\)<br/>
\(\frac{\partial y_i}{\partial z_j} = \sum\limits_{k=1}^{n}A_{i,k}\frac{\partial x_k}{\partial z_j} = \sum\limits_{k=1}^{n}A_{i,k}(\frac{\partial x}{\partial z})_{k,j}\)<br/>
因此：\(\frac{\partial y}{\partial z} = A\frac{\partial x}{\partial z}\)</p>

<p>命题3：若\(\alpha = y^\top  A x\)，其中\(y\)是一个\(m\)维的向量，\(x\)是一个\(n\)维的向量，\(z\)是一个\(l\)维的向量，\(A\)与\(z\)无关，那么\(\frac{\partial \alpha}{\partial z} = y^\top  A\frac{\partial x}{\partial x} + x^\top  A^\top  \frac{\partial y}{\partial z}\)。</p>

<p>证明：<br/>
\(\alpha = \sum\limits_{i,k}y_i A_{i,k}x_k\)<br/>
\[\begin{split}<br/>
\frac{\partial \alpha}{\partial z_j} &amp;= \sum\limits_{i,k}(\frac{\partial y_i}{\partial z_j} A_{i,k}x_k + y_i A_{i,k}\frac{\partial x_k}{\partial z_j})\\<br/>
&amp;= \sum\limits_{i=1}^{m}(x^\top A^\top )_i\frac{\partial y_i}{\partial z_j} + \sum\limits_{k=1}^{n}(y^\top A)_k\frac{\partial x_k}{\partial z_j}\\<br/>
&amp;= (x^\top A^\top \frac{\partial y}{\partial z})_j + (y^\top A\frac{\partial x}{\partial z})_j<br/>
\end{split}\]<br/>
因此，\(\frac{\partial \alpha}{\partial z} = y^\top  A\frac{\partial x}{\partial x} + x^\top  A^\top  \frac{\partial y}{\partial z}\)</p>

<p>命题4 ：若\(f\colon \mathbb{R}\to \mathbb{R}\)，\(x\)是一个\(n\)维的向量，\(z\)是一个\(l\)维的向量，\(f(x) \mathop{=}\limits^\Delta [f(x_1),f(x_2),\dots, f(x_n)]^\top\)，那么：\(\frac{\partial f(x)}{\partial z} = \mathrm{diag}(f&#39;(x))\frac{\partial x}{\partial z}\)。注意到这个命题对\(x\)是一个数值同样是正确的。</p>

<p>证明：<br/>
\(\frac{\partial f(x)_i}{\partial z_j} = f&#39;(x_i)\frac{\partial x_i}{\partial z_j}\)，这样就证明了结论。</p>

<p>命题5：若\(y = ax\)，其中\(y\)是一个\(n\)维的向量，\(x\)是一个\(n\)维的向量，\(z\)是一个\(l\)维的向量，\(a\)是一个数值，那么：\(\frac{\partial y}{\partial z} = x \frac{\partial a}{\partial z} + a \frac{\partial x}{\partial z}\)</p>

<p>证明：<br/>
\(\frac{\partial y_i}{\partial z_k} = a\frac{\partial x_i}{\partial  z_k} + \frac{\partial a}{\partial  z_k} x_i = (a\frac{\partial x}{\partial z})_{i, k}+ (x \frac{\partial a}{\partial  z})_{i, k}\\\)</p>

<p>命题6：若\(y\)是一个\(n\)维的向量，\(x\)是一个\(n\)维的向量，\(z\)是一个\(l\)维的向量，那么：\[\begin{split}\frac{\partial (x\oplus y)}{\partial z} &amp;= \frac{\partial x}{\partial  z} + \frac{\partial y}{\partial  z}\\ \frac{\partial (x\otimes y)}{\partial z} &amp;= \mathrm{diag}(y)\frac{\partial x}{\partial  z} + \mathrm{diag}(x) \frac{\partial y}{\partial  z}\\ \end{split}\]</p>

<p>证明：<br/>
\(\frac{\partial (x_i+y_i)}{\partial z_k} = \frac{\partial x_i}{\partial z_k} + \frac{\partial y_i}{\partial z_k}\)，这样就证明了第一个结论。</p>

<p>\(\frac{\partial (x_iy_i)}{\partial z_k} = \frac{\partial x_i}{\partial z_k}y_i + x_i\frac{\partial y_i}{\partial z_k} = [\mathrm{diag}(y)\frac{\partial x}{\partial  z} + \mathrm{diag}(x) \frac{\partial y}{\partial  z}]_{i,k}\)</p>

<p>命题7：若\(y=Ax\)，其中\(y\)是一个\(m\)维的向量，\(x\)是一个\(n\)维的向量，那么\(\frac{\partial y}{\partial z} = A \frac{\partial x}{\partial z} + \frac{\partial A}{\partial z}x\)。</p>

<p>证明：<br/>
\(y_i = \sum\limits_{j=1}^{n}A_{i,j}x_j\)<br/>
\(\frac{\partial y_i}{\partial z_k} = \sum\limits_{j=1}^{n}(\frac{\partial A_{i,j}}{\partial z_k}x_j + A_{i,j}\frac{\partial x_j}{\partial z_k}) =(\frac{\partial A}{\partial z}x)_{i, k} + (A\frac{\partial x}{\partial z})_{i,k}\)</p>

<h2 id="toc_3">例子</h2>

<p>\(x\)是一个\(n\)维的向量，\(y=\mathrm{softmax}(x)\)，也就是\(y_i = \frac{\exp(x_i)}{\sum\limits_{j=1}^{n} \exp(x_j)}\)，求\(\frac{\partial y}{\partial x}\)。</p>

<p>解：<br/>
我们令\(\mathbb{1}\)表示\(n\)维所有元素均为1的向量，则：<br/>
\[\begin{split}y &amp;= \mathrm{softmax}(x)\\ &amp;= \frac{\exp(x)}{\sum\limits_{i=1}^{n} \exp(x_i)}\\ &amp;= \frac{\exp(x)}{\mathrm{1}^\top \exp(x)} \end{split}\]</p>

<p>\[\begin{split}\frac{\partial y}{\partial x} &amp;= \exp(x)\frac{\partial \frac{1}{\mathbb{1}^\top \exp(x)}}{\partial  x} + \frac{1}{\mathbb{1}^\top \exp(x)}\frac{\partial \exp(x)}{\partial  x}\quad (proposition ~5)\\ &amp;= \exp(x)[-\frac{1}{(\mathbb{1}^\top \exp(x))^2}]\frac{\partial [\mathbb{1}^\top \exp(x)]}{\partial  x} + \frac{1}{\mathbb{1}^\top \exp(x)}\frac{\partial \exp(x)}{\partial  x}\quad (proposition ~4)\\<br/>
&amp;= [-\frac{\exp(x)}{(\mathbb{1}^\top \exp(x))^2}]\mathbb{1}^\top \mathrm{diag}(\exp(x)) + \frac{1}{\mathbb{1}^\top \exp(x)}\frac{\partial \exp(x)}{\partial  x}\quad (proposition ~1, 4)\\<br/>
&amp;= -\frac{\exp(x)\exp(x)^\top}{(\mathbb{1}^\top \exp(x))^2} + \frac{1}{\mathbb{1}^\top \exp(x)}\mathrm{diag}(\exp(x))\quad (proposition ~4)\\<br/>
&amp;= \frac{\mathbb{1}^\top \exp(x)\mathrm{diag}(\exp(x)) - \exp(x)\exp(x)^\top}{(\mathbb{1}^\top \exp(x))^2}\\<br/>
&amp;= \mathbb{1}^\top y\mathrm{diag}(y) - yy^\top\\<br/>
&amp;= \mathrm{diag}(y y^\top \mathbb{1}) - yy^\top\\ <br/>
&amp;= \mathrm{diag}(y) - yy^\top\\<br/>
\end{split}\]</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/4/7</span>
                    
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15543921008119.html">
                
                  <h1>信息论</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">熵</h2>

<p>假设离散随机变量X服从概率分布P。我们用它熵表示一个随机变量的不确定程度，用\(\mathbb{H} (X)\)或者是\(\mathbb{H}(p)\)表示：\[\mathbb{H}(X)\mathop{=}\limits^\Delta -\sum\limits_{k=1}^K p(X=k)\log p(X=k) = \mathop{E}\limits_{x\sim p(\cdot)}[\log(p(x))]\]</p>


                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                   <a href="15543921008119.html">Read more</a>&nbsp;&nbsp; 
                    <span class="date">2019/4/4</span>
                    
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15541232015450.html">
                
                  <h1>Noise Contrastive Estimation and Negative Sampling</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">背景</h2>

<p>在NLP领域，使用分数来得到一个概率分布是一种非常常见的形式。我们通常通过取指数然后归一化来得到一个概率分布：</p>

<p>\[<br/>
\begin{equation}<br/>
P_d(y|x;\alpha) = \frac{\exp(\mathrm{s}(y,x,\alpha))}{\sum\limits_{y\in\mathbf{Y}}\exp(s(y,x,\alpha))}<br/>
\end{equation}<br/>
\]</p>

<p>我们称\(Z(x,\alpha) = \sum\limits_{y\in\mathbf{Y}}\exp(s(y,x,\alpha))\)为partition funciton（划分函数）。 在Word2Vec中\(s(y,x,\alpha) = \alpha_y&#39;v_x\)。标准的学习过程是最大化训练样本的似然函数\[\hat\alpha=\arg\max\sum\limits_{(x,y)\in \mathbf{TD}}[\mathrm{s}(y,x,\alpha) - \ln\sum\limits_{y\in\mathbf{Y}}\exp(s(y,x,\alpha))]<br/>
\]，但是计算这个概率（和它的导数）的计算量是非常大的（和词表的大小成正比）。<br/>
为此，NLP科学家们提出了各种方法，一种是基于分类树方法（hierarchical softmax），但是它的缺点在于1. 结果对不同的树比较敏感2.对比较罕见的词效果比较好，但是对常见的单词效果比较差。另一种方法是今天我们要讲的Noise Contrastive Estimation(NCE)和Negative Sampling。</p>


                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                   <a href="15541232015450.html">Read more</a>&nbsp;&nbsp; 
                    <span class="date">2019/4/1</span>
                    
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15540423884690.html">
                
                  <h1>Word2Vec入门</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">Background</h2>

<p>@todo</p>

<h2 id="toc_1">Model Introduction</h2>

<p>在Word2Vec中，Mikolov提出了两个模型 — Continuous Bag-of-Words（CBOW）模型和Skip-gram（SG）模型。两个模型都有三层：输入层，投影层和输出层。对于CBOW模型，输入上下文预测单词；对于SG模型，通过单词预测上下文。目前来看，一般认为SG的效果好于CBOW模型。</p>


                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                   <a href="15540423884690.html">Read more</a>&nbsp;&nbsp; 
                    <span class="date">2019/3/31</span>
                    
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15540295441807.html">
                
                  <h1>Huffman树</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">问题</h2>

<p>Huffman树是为了解决这样的问题：给一段文字，能不能给出一个编码方式使得这段文字长度最短。</p>

<h2 id="toc_1">思考</h2>

<p>比如对于<code>aabc</code>，如果我们a编码成00，b编码成01，c编码成10，那么这句话表示为：<code>00000110</code>，一共有8个比特。但是如果a编码成0，b编码成10，c编码成01，那么这句话表示为<code>001011</code>，一共有6个比特。<br/>
看到了么？不同的编码方式下同样的内容对应的长度是不相同的，如何得到一段文字的最佳编码方式呢？Huffman提供了一种算法，他提供了一个贪心的解决了编码问题，并且证明了这种贪心算法得到的答案是最优解。</p>


                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                   <a href="15540295441807.html">Read more</a>&nbsp;&nbsp; 
                    <span class="date">2019/3/31</span>
                    
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <h1>张翼腾的博客</h1>
                <div class="site-des">主要关注点在于自然语言处理领域，作者在学习的过程中分享自己学到的新的内</div>
                <div class="social">










<a target="_blank" class="email" href="mailto:15307130114@fudan.edu.cn" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15547144642483.html">矩阵微分计算</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15546453666266.html">向量微分计算</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15543921008119.html">信息论</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15541232015450.html">Noise Contrastive Estimation and Negative Sampling</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15540423884690.html">Word2Vec入门</a>
			      </li>
		     
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-137432635-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-137432635-1');
</script>


  </body>
</html>
